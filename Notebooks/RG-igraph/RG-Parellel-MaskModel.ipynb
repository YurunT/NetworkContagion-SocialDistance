{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask model based on original paper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import collections\n",
    "import random\n",
    "import sys, pdb\n",
    "import site, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing, time\n",
    "from multiprocessing import Manager\n",
    "\n",
    "\n",
    "\n",
    "def create_network(mean_degree, num_nodes):\n",
    "    degree_sequence = np.random.poisson(mean_degree, num_nodes)\n",
    "    print(degree_sequence)\n",
    "    while (np.sum(degree_sequence) % 2 !=0):\n",
    "        degree_sequence = np.random.poisson(mean_degree, num_nodes)\n",
    "\n",
    "    return ig.Graph.Degree_Sequence(list(degree_sequence))\n",
    "\n",
    "def div(x, y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x*1.0/y\n",
    "\n",
    "def runExp(i, mean_degree, num_nodes, T_list, mask_prob):\n",
    "    network = create_network(mean_degree, num_nodes)\n",
    "    size = evolution(network, T_list, mask_prob)\n",
    "    fractionDic[i] = div(size,num_nodes)\n",
    "#     infectedPerStDic[i] = [div(size1,num_nodes), div(size2,num_nodes)]\n",
    "\n",
    "def infected_rule(edge_trans_dict, susceptible_nodes):\n",
    "    new_nodes_list = set()\n",
    "    if (len(edge_trans_dict.keys()) != 0):\n",
    "        for node in edge_trans_dict.keys():\n",
    "            trial_list = edge_trans_dict[node]\n",
    "            random.shuffle(trial_list) # Shuffle\n",
    "            for trans in trial_list:\n",
    "                if random.random() < trans:\n",
    "                    susceptible_nodes.remove(node)\n",
    "                    new_nodes_list.add(node)\n",
    "                    break\n",
    "    return new_nodes_list\n",
    "\n",
    "def evolution(g, t_list, mask_prob):\n",
    "    g.simplify()\n",
    "    \n",
    "    node_set = set(g.vs.indices)\n",
    "    num_nodes = len(node_set)\n",
    "    \n",
    "    masks_set = np.random.binomial(1, mask_prob, num_nodes)\n",
    "    mask_dict = dict(zip(np.linspace(0, num_nodes - 1, num_nodes, dtype = int), masks_set))\n",
    "\n",
    "    susceptible_nodes = node_set\n",
    "    strain_set = set([int(np.random.random_integers(0, num_nodes - 1))])\n",
    "    susceptible_nodes = susceptible_nodes.difference(strain_set)\n",
    "    new_nodes_list = strain_set\n",
    "    \n",
    "    \n",
    "    while(len(new_nodes_list)):\n",
    "        edge_trans_dict = collections.defaultdict(list)\n",
    "        \n",
    "        \n",
    "        for node in strain_set:\n",
    "            strain_neighbors_list = []\n",
    "            neighbors += g.neighbors(node)\n",
    "            \n",
    "            for neighbor_node in neighbors:\n",
    "                if neighbor_node not in susceptible_nodes: continue\n",
    "\n",
    "                if  mask_dict[node] == 1 and mask_dict[neighbor_node] == 0:\n",
    "                    T_edge = t_list[0]\n",
    "                elif mask_dict[node] == 1 and mask_dict[neighbor_node] == 1:\n",
    "                    T_edge = t_list[1]\n",
    "                elif mask_dict[node] == 0 and mask_dict[neighbor_node] == 0:\n",
    "                    T_edge = t_list[2]\n",
    "                else:\n",
    "                    T_edge = t_list[3]\n",
    "                \n",
    "                edge_trans_dict[neighbor_node].append(T_edge) \n",
    "\n",
    "            \n",
    "        new_nodes_list = infected_rule(edge_trans_dict, susceptible_nodes)\n",
    "\n",
    "        strain_set = strain_set.union(new_nodes_list)\n",
    "    return len(strain_set)\n",
    "\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser(description = 'Parameters')\n",
    "    parser.add_argument('-m', type = float, nargs = '+', default = np.arange(1, 10.1, 0.1), help='np.linspace(0.001, 7, 50) (default); list of mean degree: you can type 1 3 5')\n",
    "    parser.add_argument('-n', type = int, default = 200000, help='10,000 (default); the number of nodes')\n",
    "    parser.add_argument('-e', type = int, default = 50, help='100 (default); the number of experiments')\n",
    "    parser.add_argument('-t1', type = float, default = 0.2, help='0.5 (default); the transmissibility of strain-1')\n",
    "    parser.add_argument('-t2', type = float, default = 0.5, help='0.5 (default); the transmissibility of strain-2')\n",
    "    parser.add_argument('-m1', type = float, default = 0.9, help='0.5 (default); the mutation probability from 1 to 1')\n",
    "    parser.add_argument('-m2', type = float, default = 1.0, help='0.5 (default); the mutation probability from 2 to 2')\n",
    "    parser.add_argument('-thrVal', type = float, default = 0.005, help='0.001 (default); the treshold to consider a component giant')\n",
    "    parser.add_argument('-numCores', type = int, default = 12, help='number of Cores')\n",
    "    parser.add_argument('-logName', default = 'logfile', help='The name of the log file')\n",
    "    parser.add_argument('-i', type = int, default = 1, help='1 (default); starting from type-i node')\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "####### Added by Yurun #######\n",
    "def draw_figures(mean_degree_list, Prob_Emergence, AvgValidSize, AvgSize, ExpPath):\n",
    "    figure_path = ExpPath + '/' + 'Figures'\n",
    "    if not os.path.exists(figure_path):\n",
    "        os.mkdir(figure_path)\n",
    "    \n",
    "    ### Probability of Emergence ###    \n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, Prob_Emergence, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Prob of Emergence\")\n",
    "    title = \"Probability of Emergence for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "    ### Epidemic Size ###\n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, AvgValidSize, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Epidemic Size\")\n",
    "    title = \"Epidemic Size for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "    ### Infected Frac ###\n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, AvgSize, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Infected Frac\")\n",
    "    title = \"Infected Frac for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "# paras = parse_args(sys.argv[1:])\n",
    "# mean_degree_list = paras.m\n",
    "# t1 = paras.t1\n",
    "# t2 = paras.t2\n",
    "# m1 = paras.m1\n",
    "# m2 = paras.m2\n",
    "# num_nodes = paras.n\n",
    "# numExp = paras.e\n",
    "# start_strain = paras.i\n",
    "# num_cores = min(paras.numCores,multiprocessing.cpu_count())\n",
    "# thrVal = paras.thrVal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = np.random.poisson(5, 2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(degree_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node number: 2000\n",
      "Exp number: 10\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'neighbors' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-7-98ed746675bc>\", line 33, in runExp\n  File \"<ipython-input-7-98ed746675bc>\", line 71, in evolution\nUnboundLocalError: local variable 'neighbors' referenced before assignment\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3d6f25f71481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mttlFrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunExp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_degree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_prob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumExp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;31m#     for exp in range(numExp):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#         runExp(exp, mean_degree,num_nodes, T_list, mask_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytian/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytian/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytian/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytian/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ytian/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'neighbors' referenced before assignment"
     ]
    }
   ],
   "source": [
    "mean_degree_list = np.linspace(0, 10, 50)\n",
    "\n",
    "t1 = 0.0048\n",
    "t2 = 0.032\n",
    "t3 = 0.32\n",
    "t4 = 0.048\n",
    "\n",
    "mask_prob = 0.6\n",
    "\n",
    "num_nodes = 2000\n",
    "numExp = 10\n",
    "\n",
    "start_strain = 1\n",
    "num_cores = min(2,multiprocessing.cpu_count())\n",
    "thrVal = 0.005\n",
    "\n",
    "print(\"Node number:\", num_nodes)\n",
    "print(\"Exp number:\", numExp)\n",
    "\n",
    "T_list = [t1, t2, t3, t4]\n",
    "ff = open(\"log1\"+'Det','w+')\n",
    "f = open(\"log1\", 'w+')\n",
    "\n",
    "########### Added by Yurun ###########\n",
    "Prob_Emergence = list()\n",
    "AvgValidSize = list()\n",
    "AvgSize = list()\n",
    "StdValidSize = list()\n",
    "infSt1 = list()\n",
    "infSt2 = list()\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "timeExp = now.strftime(\"%m%d%H:%M\")\n",
    "ExpPath = 'Paper_Mask_Results/' + timeExp + '_n' + str(num_nodes) + '_e' + str(numExp)\n",
    "\n",
    "if not os.path.exists(ExpPath):\n",
    "    os.makedirs(ExpPath)\n",
    "\n",
    "#### Paper Code ####\n",
    "for mean_degree in mean_degree_list:\n",
    "    a = time.time()\n",
    "    ttlEpidemicsSize = 0\n",
    "    numEpidemics = 0\n",
    "    Epidemics = []\n",
    "    EpidemicsPerSt = [0,0,0]\n",
    "    fractionDic = Manager().dict()\n",
    "    infectedPerStDic = Manager().dict()\n",
    "    ttlFrac = 0\n",
    "    \n",
    "    Parallel(n_jobs = num_cores)(delayed(runExp)(i, mean_degree,num_nodes, T_list, mask_prob) for i in range(numExp))\n",
    "#     for exp in range(numExp):\n",
    "#         runExp(exp, mean_degree,num_nodes, T_list, mask_prob) \n",
    "\n",
    "    for ii in range(numExp):\n",
    "        if fractionDic[ii] >= thrVal:\n",
    "            numEpidemics += 1\n",
    "            ttlEpidemicsSize += fractionDic[ii]\n",
    "            Epidemics.append(fractionDic[ii])\n",
    "\n",
    "        ttlFrac += fractionDic[ii]\n",
    "\n",
    "    if len(Epidemics) == 0:\n",
    "        Epidemics.append(0)\n",
    "\n",
    "    \n",
    "    ######### Record the results for this Mean Degree ##########    \n",
    "    Prob_Emergence.append(numEpidemics*1.0/(numExp))\n",
    "    AvgValidSize.append(div(ttlEpidemicsSize*1.0, numEpidemics))\n",
    "    AvgSize.append(ttlFrac*1.0/numExp)\n",
    "    StdValidSize.append(np.std(Epidemics))\n",
    "    infSt1.append(div(EpidemicsPerSt[0],numEpidemics))\n",
    "    infSt2.append(div(EpidemicsPerSt[1],numEpidemics))\n",
    "\n",
    "######### Save the results for all Mean Degrees ########## \n",
    "draw_figures(mean_degree_list, Prob_Emergence, AvgValidSize, AvgSize, ExpPath)\n",
    "\n",
    "setting_path = ExpPath + '/' + 'Settings'\n",
    "if not os.path.exists(setting_path):\n",
    "    os.mkdir(setting_path)\n",
    "    \n",
    "res_paths = ExpPath + '/' + 'Results'\n",
    "if not os.path.exists(res_paths):\n",
    "    os.mkdir(res_paths)\n",
    "\n",
    "### Experiment Parameters ###\n",
    "paras = dict()\n",
    "paras['ExpN'] = numExp\n",
    "paras['nodeN'] = num_nodes\n",
    "paras['threshold'] = thrVal\n",
    "\n",
    "with open(setting_path + '/paras.json', 'w') as fp:\n",
    "    json.dump(paras, fp)\n",
    "    \n",
    "### Degree list ###\n",
    "np.save(setting_path + '/mean_degree_list.npy', np.array(mean_degree_list)) \n",
    "    \n",
    "### Transmissibilites and mutation probs for Mutation Model ###\n",
    "np.save(setting_path + '/trans_dict_mu.npy', np.array(T_list)) \n",
    "\n",
    "\n",
    "### Results ###\n",
    "np.save(res_paths + '/Prob_Emergence.npy', np.array(Prob_Emergence)) \n",
    "np.save(res_paths + '/AvgValidSize.npy', np.array(AvgValidSize)) \n",
    "np.save(res_paths + '/StdValidSize.npy', np.array(StdValidSize)) \n",
    "np.save(res_paths + '/infSt1.npy', np.array(infSt1)) \n",
    "np.save(res_paths + '/infSt2.npy', np.array(infSt2)) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ytian)",
   "language": "python",
   "name": "ytian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
