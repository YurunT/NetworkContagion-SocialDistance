{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node number: 10000\n",
      "Exp number: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytian/.conda/envs/ytian/lib/python3.7/site-packages/ipykernel_launcher.py:61: DeprecationWarning: This function is deprecated. Please call randint(0, 9999 + 1) instead\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ca60a5f775fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;31m#                                  for i in range(numExp))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumExp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mrunExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_degree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumExp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ca60a5f775fa>\u001b[0m in \u001b[0;36mrunExp\u001b[0;34m(i, mean_degree, num_nodes, T_list, mutation_probability)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunExp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_degree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mfractionDic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ca60a5f775fa>\u001b[0m in \u001b[0;36mcreate_network\u001b[0;34m(mean_degree, num_nodes)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdegree_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDegree_Sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import collections\n",
    "import random\n",
    "import sys, pdb\n",
    "import site, os\n",
    "# site.addsitedir('/afs/ece.cmu.edu/usr/reletreb/dep/lib/python2.7/site-packages')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing, time\n",
    "from multiprocessing import Manager\n",
    "\n",
    "\n",
    "\n",
    "def create_network(mean_degree, num_nodes):\n",
    "    degree_sequence = np.random.poisson(mean_degree, num_nodes)\n",
    "    while (np.sum(degree_sequence) % 2 !=0):\n",
    "        degree_sequence = np.random.poisson(mean_degree, num_nodes)\n",
    "\n",
    "    return ig.Graph.Degree_Sequence(list(degree_sequence))\n",
    "\n",
    "def div(x, y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x*1.0/y\n",
    "\n",
    "def runExp(i, mean_degree,num_nodes, T_list, mutation_probability):\n",
    "    network = create_network(mean_degree, num_nodes)\n",
    "    size, size1, size2 = evolution(network, T_list, mutation_probability)\n",
    "    fractionDic[i] = div(size,num_nodes)\n",
    "    infectedPerStDic[i] = [div(size1,num_nodes), div(size2,num_nodes)]\n",
    "\n",
    "def infected_rule(infected_neighbors_dict, t_list, susceptible_nodes, num_strain, mutation_prob):\n",
    "    new_nodes_list = [set(), set()]\n",
    "    if len(infected_neighbors_dict.keys()) != 0:\n",
    "        for node in infected_neighbors_dict:\n",
    "            trial_list = infected_neighbors_dict[node]\n",
    "            random.shuffle(trial_list)\n",
    "            for neighbor in trial_list:\n",
    "                if random.random() < t_list[neighbor]:\n",
    "                    susceptible_nodes.remove(node)\n",
    "\n",
    "                    strain_type_idx = neighbor % num_strain\n",
    "                    next_strain_type_idx = (neighbor + 1) % num_strain\n",
    "                    if random.random() < mutation_prob[neighbor]:\n",
    "                        new_nodes_list[strain_type_idx].add(node)\n",
    "                    else:\n",
    "                        new_nodes_list[next_strain_type_idx].add(node)\n",
    "                    break\n",
    "    return new_nodes_list\n",
    "\n",
    "def evolution(g, t_list, mutation_prob):\n",
    "    g.simplify()\n",
    "    node_set = set(g.vs.indices)\n",
    "    num_nodes = len(node_set)\n",
    "    if start_strain == 1:\n",
    "        strain_set_1 = set([int(np.random.random_integers(0, num_nodes - 1))])\n",
    "        strain_set_2 = set()\n",
    "    elif start_strain == 2:\n",
    "        strain_set_1 = set()\n",
    "        strain_set_2 = set([int(np.random.random_integers(0, num_nodes - 1))])\n",
    "    else:\n",
    "        exit()\n",
    "    strain_list = [strain_set_1, strain_set_2]\n",
    "    num_strain = len(strain_list)\n",
    "\n",
    "    susceptible_nodes = node_set\n",
    "    for strain_set in strain_list:\n",
    "        susceptible_nodes = susceptible_nodes.difference(strain_set)\n",
    "    new_nodes_list = [strain_set_1, strain_set_2]\n",
    "\n",
    "    while(sum([len(new_nodes) for new_nodes in new_nodes_list])):\n",
    "        \n",
    "        neighbor_dict = collections.defaultdict(list)\n",
    "\n",
    "        for strain_type, strain_set in enumerate(new_nodes_list):\n",
    "            strain_neighbors_list = []\n",
    "            for node in strain_set:\n",
    "                strain_neighbors_list += g.neighbors(node)\n",
    "            if len(strain_neighbors_list) == 0: continue\n",
    "                \n",
    "            for node in strain_neighbors_list:\n",
    "                if node not in susceptible_nodes: continue\n",
    "                neighbor_dict[node].append(strain_type)\n",
    "        new_nodes_list = infected_rule(neighbor_dict, t_list, susceptible_nodes, num_strain, mutation_prob)\n",
    "\n",
    "        strain_list = [strain_list[s_idx].union(s) for s_idx, s in enumerate(new_nodes_list)]\n",
    "    num_infected = sum([len(s) for s in strain_list])\n",
    "    num_infected1, num_infected2 = map(len, strain_list)\n",
    "    return num_infected, num_infected1, num_infected2\n",
    "\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser(description = 'Parameters')\n",
    "    parser.add_argument('-m', type = float, nargs = '+', default = np.arange(1, 10.1, 0.1), help='np.linspace(0.001, 7, 50) (default); list of mean degree: you can type 1 3 5')\n",
    "    parser.add_argument('-n', type = int, default = 200000, help='10,000 (default); the number of nodes')\n",
    "    parser.add_argument('-e', type = int, default = 50, help='100 (default); the number of experiments')\n",
    "    parser.add_argument('-t1', type = float, default = 0.2, help='0.5 (default); the transmissibility of strain-1')\n",
    "    parser.add_argument('-t2', type = float, default = 0.5, help='0.5 (default); the transmissibility of strain-2')\n",
    "    parser.add_argument('-m1', type = float, default = 0.9, help='0.5 (default); the mutation probability from 1 to 1')\n",
    "    parser.add_argument('-m2', type = float, default = 1.0, help='0.5 (default); the mutation probability from 2 to 2')\n",
    "    parser.add_argument('-thrVal', type = float, default = 0.005, help='0.001 (default); the treshold to consider a component giant')\n",
    "    parser.add_argument('-numCores', type = int, default = 12, help='number of Cores')\n",
    "    parser.add_argument('-logName', default = 'logfile', help='The name of the log file')\n",
    "    parser.add_argument('-i', type = int, default = 1, help='1 (default); starting from type-i node')\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "####### Added by Yurun #######\n",
    "def draw_figures(mean_degree_list, Prob_Emergence, AvgValidSize, AvgSize, ExpPath):\n",
    "    figure_path = ExpPath + '/' + 'Figures'\n",
    "    if not os.path.exists(figure_path):\n",
    "#         print(\"make path \", figure_path)\n",
    "        os.mkdir(figure_path)\n",
    "    \n",
    "    ### Probability of Emergence ###    \n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, Prob_Emergence, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Prob of Emergence\")\n",
    "    title = \"Probability of Emergence for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "    ### Epidemic Size ###\n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, AvgValidSize, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Epidemic Size\")\n",
    "    title = \"Epidemic Size for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "    ### Infected Frac ###\n",
    "    plt.figure()\n",
    "    plt.plot(mean_degree_list, AvgSize, 'go')\n",
    "    plt.xlabel(\"Mean Degree\")\n",
    "    plt.ylabel(\"Infected Frac\")\n",
    "    title = \"Infected Frac for Paper Model\"\n",
    "    plt.title(title)\n",
    "    plt.savefig(figure_path + '/' + title.replace(\" \", \"_\") + '.png')\n",
    "    \n",
    "# paras = parse_args(sys.argv[1:])\n",
    "# mean_degree_list = paras.m\n",
    "# t1 = paras.t1\n",
    "# t2 = paras.t2\n",
    "# m1 = paras.m1\n",
    "# m2 = paras.m2\n",
    "# num_nodes = paras.n\n",
    "# numExp = paras.e\n",
    "# start_strain = paras.i\n",
    "# num_cores = min(paras.numCores,multiprocessing.cpu_count())\n",
    "# thrVal = paras.thrVal\n",
    "\n",
    "\n",
    "mean_degree_list = np.linspace(0, 10, 50)\n",
    "t1 = 0.02112\n",
    "t2 = 0.1568\n",
    "\n",
    "m1 = 0.9090909090909091\n",
    "m2 = 0.8163265306122449\n",
    "\n",
    "num_nodes = 10000\n",
    "numExp = 100000\n",
    "\n",
    "start_strain = 1\n",
    "num_cores = min(2,multiprocessing.cpu_count())\n",
    "thrVal = 0.005\n",
    "\n",
    "print(\"Node number:\", num_nodes)\n",
    "print(\"Exp number:\", numExp)\n",
    "\n",
    "T_list = [t1, t2]\n",
    "mutation_probability = [m1, m2]\n",
    "ff = open(\"log1\"+'Det','w+')\n",
    "f = open(\"log1\", 'w+')\n",
    "\n",
    "########### Added by Yurun ###########\n",
    "Prob_Emergence = list()\n",
    "AvgValidSize = list()\n",
    "AvgSize = list()\n",
    "StdValidSize = list()\n",
    "infSt1 = list()\n",
    "infSt2 = list()\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "timeExp = now.strftime(\"%m%d%H:%M\")\n",
    "ExpPath = 'PaperCode_Results/' + timeExp + '_n' + str(num_nodes) + '_e' + str(numExp)\n",
    "\n",
    "if not os.path.exists(ExpPath):\n",
    "#     print(\"make path \", ExpPath)\n",
    "    os.makedirs(ExpPath)\n",
    "\n",
    "#### Paper Code ####\n",
    "for mean_degree in mean_degree_list:\n",
    "    a = time.time()\n",
    "    ttlEpidemicsSize = 0\n",
    "    numEpidemics = 0\n",
    "    Epidemics = []\n",
    "    EpidemicsPerSt = [0,0,0]\n",
    "    fractionDic = Manager().dict()\n",
    "    infectedPerStDic = Manager().dict()\n",
    "    ttlFrac = 0\n",
    "#     with parallel_backend('multiprocessing'):\n",
    "#     Parallel(n_jobs = num_cores)(delayed(runExp)(i, mean_degree,num_nodes, T_list, mutation_probability) \n",
    "#                                  for i in range(numExp))\n",
    "    for exp in range(numExp):\n",
    "        runExp(exp, mean_degree,num_nodes, T_list, mutation_probability) \n",
    "\n",
    "    for ii in range(numExp):\n",
    "        resultsFrac = 'meanDeg: {0} Size: {1} infSt1: {2} infSt2: {3}\\n'.format(mean_degree, fractionDic[ii], infectedPerStDic[ii][0],infectedPerStDic[ii][1] )\n",
    "\n",
    "        if fractionDic[ii] >= thrVal:\n",
    "            ff.write(resultsFrac)\n",
    "            ff.flush()\n",
    "            numEpidemics += 1\n",
    "            ttlEpidemicsSize += fractionDic[ii]\n",
    "            Epidemics.append(fractionDic[ii])\n",
    "            EpidemicsPerSt[0] += infectedPerStDic[ii][0]\n",
    "            EpidemicsPerSt[1] += infectedPerStDic[ii][1]\n",
    "\n",
    "        ttlFrac += fractionDic[ii]\n",
    "\n",
    "    if len(Epidemics) == 0:\n",
    "        Epidemics.append(0)\n",
    "\n",
    "\n",
    "    results = 'numExp: {0} Threshold: {1} n: {2} meanDeg: {3} Prob: {4} AvgValidSize: {5} StdValidSize: {6} infSt1: {7} infSt2: {8} AvgSize: {9} T: {10} Mu: {11} Time: {12} \\n'.format(\n",
    "               numExp, thrVal , num_nodes, mean_degree, numEpidemics*1.0/(numExp), div(ttlEpidemicsSize*1.0,numEpidemics), np.std(Epidemics) , div(EpidemicsPerSt[0],numEpidemics),div(EpidemicsPerSt[1],numEpidemics), ttlFrac*1.0/numExp,' '.join(map(str, T_list)), ' '.join(map(str, mutation_probability)), time.time()-a )\n",
    "    \n",
    "#     print(results)\n",
    "    f.write(results)\n",
    "    f.flush()\n",
    "    \n",
    "    ######### Record the results for this Mean Degree ##########    \n",
    "    Prob_Emergence.append(numEpidemics*1.0/(numExp))\n",
    "    AvgValidSize.append(div(ttlEpidemicsSize*1.0, numEpidemics))\n",
    "    AvgSize.append(ttlFrac*1.0/numExp)\n",
    "    StdValidSize.append(np.std(Epidemics))\n",
    "    infSt1.append(div(EpidemicsPerSt[0],numEpidemics))\n",
    "    infSt2.append(div(EpidemicsPerSt[1],numEpidemics))\n",
    "\n",
    "######### Save the results for all Mean Degrees ########## \n",
    "draw_figures(mean_degree_list, Prob_Emergence, AvgValidSize, AvgSize, ExpPath)\n",
    "\n",
    "setting_path = ExpPath + '/' + 'Settings'\n",
    "if not os.path.exists(setting_path):\n",
    "    os.mkdir(setting_path)\n",
    "    \n",
    "res_paths = ExpPath + '/' + 'Results'\n",
    "if not os.path.exists(res_paths):\n",
    "    os.mkdir(res_paths)\n",
    "\n",
    "### Experiment Parameters ###\n",
    "paras = dict()\n",
    "paras['ExpN'] = numExp\n",
    "paras['nodeN'] = num_nodes\n",
    "paras['threshold'] = thrVal\n",
    "\n",
    "with open(setting_path + '/paras.json', 'w') as fp:\n",
    "    json.dump(paras, fp)\n",
    "    \n",
    "### Degree list ###\n",
    "np.save(setting_path + '/mean_degree_list.npy', np.array(mean_degree_list)) \n",
    "    \n",
    "### Transmissibilites and mutation probs for Mutation Model ###\n",
    "np.save(setting_path + '/trans_dict_mu.npy', np.array(T_list)) \n",
    "np.save(setting_path + '/mu_dict.npy', np.array(mutation_probability))\n",
    "\n",
    "\n",
    "### Results ###\n",
    "np.save(res_paths + '/Prob_Emergence.npy', np.array(Prob_Emergence)) \n",
    "np.save(res_paths + '/AvgValidSize.npy', np.array(AvgValidSize)) \n",
    "np.save(res_paths + '/StdValidSize.npy', np.array(StdValidSize)) \n",
    "np.save(res_paths + '/infSt1.npy', np.array(infSt1)) \n",
    "np.save(res_paths + '/infSt2.npy', np.array(infSt2)) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ytian)",
   "language": "python",
   "name": "ytian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
